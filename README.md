# LLM ëª¨ë¸ ë° í”„ë¡¬í”„íŠ¸ í‰ê°€ í”Œë«í¼

ì´ í”„ë¡œì íŠ¸ëŠ” `promptfoo`ì™€ `litellm`ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì˜ ì„±ëŠ¥ê³¼ ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì¡°í•©ì„ ì²´ê³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ê³  í‰ê°€í•˜ê¸° ìœ„í•œ í”Œë«í¼ì…ë‹ˆë‹¤.

## ì£¼ìš” ê¸°ìˆ 

- **[promptfoo](https://www.promptfoo.dev/):** LLM ì•±ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬. í”„ë¡¬í”„íŠ¸, ëª¨ë¸, í’ˆì§ˆ í‰ê°€ë¥¼ ìë™í™”í•©ë‹ˆë‹¤.
- **[litellm](https://www.litellm.ai/):** 100ê°œ ì´ìƒì˜ LLM APIë¥¼ OpenAI í‘œì¤€ í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
PromptFoo â†’ custom-litellm-provider.js â†’ litellm_provider.py â†’ LiteLLM â†’ API
```

### í•µì‹¬ êµ¬ì„±ìš”ì†Œ
1. **promptfooconfig.yaml**: í…ŒìŠ¤íŠ¸ ì •ì˜ ë° í‰ê°€ ì„¤ì •
2. **custom-litellm-provider.js**: PromptFoo JavaScript ì»¤ìŠ¤í…€ provider
3. **litellm_provider.py**: ë‹¤ì¤‘ LLM API í†µí•© Python ìŠ¤í¬ë¦½íŠ¸
4. **.env**: API í‚¤ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •

## ì‹œì‘í•˜ê¸°

### 1. ì‚¬ì „ ì¤€ë¹„

- [Node.js](https://nodejs.org/) (v18 ì´ìƒ) ë° npm
- Python (v3.10 ì´ìƒ)
- í•„ìš”í•œ LLM API í‚¤ë“¤

### 2. í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# 1. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
npm install -g promptfoo

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ ì‹¤ì œ API í‚¤ ì…ë ¥
```

### 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼)

```bash
# í•„ìˆ˜ API í‚¤ë“¤
OPENAI_API_KEY=sk-proj-...
GEMINI_API_KEY=AIzaSy...
PERPLEXITY_API_KEY=pplx-...

# ì„ íƒì  API í‚¤ë“¤  
OPENROUTER_API_KEY=sk-or-...
ANTHROPIC_API_KEY=sk-ant-...
COHERE_API_KEY=...

# Ollama ì„¤ì • (ë¡œì»¬ ì‚¬ìš©ì‹œ)
OLLAMA_API_BASE=http://localhost:11434
```

### 4. í‰ê°€ ì‹¤í–‰

```bash
# ì „ì²´ í‰ê°€ ì‹¤í–‰
npx promptfoo eval --config promptfooconfig.yaml

# ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
npx promptfoo eval --config promptfooconfig.yaml --filter-first-n 1

# íŠ¹ì • ëª¨ë¸ë§Œ í…ŒìŠ¤íŠ¸
npx promptfoo eval --config promptfooconfig.yaml --filter-providers "gpt-3.5-turbo"

# ì›¹ UIë¡œ ê²°ê³¼ í™•ì¸
npx promptfoo view
```

## ğŸš€ **ëŒ€í‘œ ì‹¤í—˜ ë°©ì‹ ë° ì˜ˆì‹œ**

### ğŸ“Š **ì‹¤í—˜ ë°©ì‹ 1: CSV ê¸°ë°˜ ì •ë°€ ì¡°í•©** 
> ğŸ¯ **ëª©ì **: ì—‘ì…€/êµ¬ê¸€ì‹œíŠ¸ì²˜ëŸ¼ ì§ê´€ì ì¸ ì¡°í•© ê´€ë¦¬  
> ğŸ“ **ì„¤ì • íŒŒì¼**: `youtube_summary.yaml` + `tests/test.csv`

**âœ¨ ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# 1. CSV íŒŒì¼ í¸ì§‘
vim tests/test.csv

# 2. ì‹¤í–‰
npx promptfoo eval -c youtube_summary.yaml
```

**ğŸ“ CSV í…œí”Œë¦¿** (`tests/test.csv`):
```csv
query,temperature,model,provider,prompt
"AI ì—ì´ì „íŠ¸ ìµœì‹  ì—°êµ¬",0.7,gpt-3.5-turbo,openai,summary_prompt
"ë©€í‹°ëª¨ë‹¬ LLM ë™í–¥",0.5,gemini-1.5-flash,google,twitter_style_prompt
"RAG ì‹œìŠ¤í…œ ì„¤ê³„ íŒ¨í„´",0.3,sonar,perplexity,academic_style_prompt
"Test Time Compute",0.8,gemma3:12b,ollama,summary_prompt
```

**ğŸ”¥ ì¥ì **: 
- âœ… ì •í™•í•œ ì¡°í•© ì œì–´ (í–‰ë³„ë¡œ ë…ë¦½ì )
- âœ… ë¹„ê°œë°œìë„ ì‰½ê²Œ ìˆ˜ì • ê°€ëŠ¥
- âœ… ë¹ ë¥¸ A/B í…ŒìŠ¤íŠ¸

---

### ğŸ”¬ **ì‹¤í—˜ ë°©ì‹ 2: YAML ìë™ ì¡°í•© ë§¤íŠ¸ë¦­ìŠ¤**
> ğŸ¯ **ëª©ì **: í”„ë¡¬í”„íŠ¸Ã—ëª¨ë¸ ì „ì²´ ì¡°í•© ìë™ ìƒì„±  
> ğŸ“ **ì„¤ì • íŒŒì¼**: `promptfooconfig.yaml`

**âœ¨ ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# ë³µí•© ì‹¤í—˜ ì‹¤í–‰ (3 í”„ë¡¬í”„íŠ¸ Ã— 4 ëª¨ë¸ = 12ê°€ì§€ ì¡°í•©)
npx promptfoo eval -c promptfooconfig.yaml

# ë¹ ë¥¸ ê°œë°œ í…ŒìŠ¤íŠ¸ (ì²« ë²ˆì§¸ë§Œ)
npx promptfoo eval -c promptfooconfig.yaml --filter-first-n 1
```

**ğŸ“ ì„¤ì • ì˜ˆì‹œ**:
```yaml
tests:
  - description: "ğŸ“ˆ í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ë³„ ìš”ì•½ í’ˆì§ˆ ë§¤íŠ¸ë¦­ìŠ¤"
    prompts:
      - "prompts/basic.txt"              # ê¸°ë³¸ ìŠ¤íƒ€ì¼
      - "prompts/summary/academic_style_prompt.txt"  # í•™ìˆ  ìŠ¤íƒ€ì¼  
      - "prompts/summary/twitter_style_prompt.txt"   # ì†Œì…œë¯¸ë””ì–´ ìŠ¤íƒ€ì¼
    providers:
      - config: {model: gpt-3.5-turbo}    # OpenAI
      - config: {model: gemini-flash}     # Google
      - config: {model: perplexity-sonar} # Perplexity
      - config: {model: ollama/gemma3:12b} # Local
    vars:
      query: file://queries/summary_query.txt
    # ğŸ”„ ê²°ê³¼: 3Ã—4 = 12ê°€ì§€ ì¡°í•© ìë™ ìƒì„±
```

**ğŸ”¥ ì¥ì **:
- âœ… ëŒ€ê·œëª¨ ë¹„êµ ì‹¤í—˜
- âœ… ì²´ê³„ì  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- âœ… í†µê³„ì  ìœ ì˜ì„± í™•ë³´

---

### âš¡ **ì‹¤í—˜ ë°©ì‹ 3: ê°„í¸ í”„ë¡œí† íƒ€ì´í•‘** 
> ğŸ¯ **ëª©ì **: ë¹ ë¥¸ ì•„ì´ë””ì–´ ê²€ì¦ ë° ê°œë°œ  
> ğŸ“ **ì„¤ì • íŒŒì¼**: `test.yaml`

**âœ¨ ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# ê°„ë‹¨í•œ 2Ã—3 ì¡°í•© í…ŒìŠ¤íŠ¸
npx promptfoo eval -c test.yaml
```

**ğŸ“ ì„¤ì • ì˜ˆì‹œ**:
```yaml
description: "ğŸ’¡ ë¹ ë¥¸ í”„ë¡¬í”„íŠ¸ ë¹„êµ"
prompts:
  - file://prompts/summary_prompt.txt    # ì¼ë°˜ ìš”ì•½
  - file://prompts/twitter_style_prompt.txt  # íŠ¸ìœ„í„° ìŠ¤íƒ€ì¼

providers:
  - id: "google:gemini-1.5-flash"
  - id: "perplexity:sonar" 
  - id: "ollama:gemma3"

defaultTest:
  vars:
    query: "Test Time Compute, Reasoning, LLM Agents ìµœì‹  ì—°êµ¬"
    temperature: 0.7
```

**ğŸ”¥ ì¥ì **:
- âœ… 30ì´ˆ ë‚´ ì‹¤í—˜ ì‹œì‘
- âœ… ì•„ì´ë””ì–´ ë¹ ë¥¸ ê²€ì¦
- âœ… ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì 

---

### ğŸ¬ **ì‹¤í—˜ ë°©ì‹ 4: ë„ë©”ì¸ íŠ¹í™” í…ŒìŠ¤íŠ¸**
> ğŸ¯ **ëª©ì **: ìœ íŠœë¸Œ ì˜ìƒ, ë…¼ë¬¸ ë“± íŠ¹ì • ë„ë©”ì¸ ìµœì í™”  
> ğŸ“ **ì„¤ì • íŒŒì¼**: `youtube_summary.yaml`

**âœ¨ ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# ìœ íŠœë¸Œ ì˜ìƒ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë¹„êµ
npx promptfoo eval -c youtube_summary.yaml
```

**ğŸ“ ì„¤ì • ì˜ˆì‹œ**:
```yaml
description: "ğŸ“º ìœ íŠœë¸Œ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ìµœì í™”"
prompts:
  - file://prompts/summary/v09.txt      # ê°„ê²°í˜•
  - file://prompts/summary/v111.txt     # ìƒì„¸í˜•
  - file://prompts/summary/v2.txt       # êµ¬ì¡°í™”í˜•

defaultTest:
  vars:
    video_input:
      file_data:
        file_uri: "https://youtu.be/Lv3QwcAcDnA"
        mime_type: "video/*"
    query: "ì´ ë¹„ë””ì˜¤ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜"
```

**ğŸ”¥ ì¥ì **:
- âœ… ë„ë©”ì¸ë³„ ìµœì í™”
- âœ… ì‹¤ì œ ì‚¬ìš© ì¼€ì´ìŠ¤ ë°˜ì˜
- âœ… ì „ë¬¸ í‰ê°€ ê¸°ì¤€

---

## ğŸ› ï¸ **ì‹¤í—˜ ì‹¤í–‰ ëª…ë ¹ì–´ ëª¨ìŒ**

### **ê°œë°œ/í…ŒìŠ¤íŠ¸ ë‹¨ê³„**
```bash
# ğŸš€ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… (2Ã—3=6ê°€ì§€)
npx promptfoo eval -c test.yaml

# ğŸ§ª ì²« ë²ˆì§¸ ì¡°í•©ë§Œ í…ŒìŠ¤íŠ¸
npx promptfoo eval -c test.yaml --filter-first-n 1

# ğŸ“Š íŠ¹ì • ëª¨ë¸ë§Œ í…ŒìŠ¤íŠ¸
npx promptfoo eval --filter-providers "gemini"
```

### **ì •ë°€ ì‹¤í—˜ ë‹¨ê³„**  
```bash
# ğŸ“ˆ ì •ë°€ ì¡°í•© ì‹¤í—˜ (CSV ê¸°ë°˜)
npx promptfoo eval -c youtube_summary.yaml

# ğŸ”¬ ì „ì²´ ë§¤íŠ¸ë¦­ìŠ¤ ì‹¤í—˜ (3Ã—4=12ê°€ì§€)
npx promptfoo eval -c promptfooconfig.yaml

# ğŸ“‹ ê²°ê³¼ ì›¹ UIë¡œ í™•ì¸
npx promptfoo view
```

### **í”„ë¡œë•ì…˜ ê²€ì¦**
```bash
# ğŸ¯ ë„ë©”ì¸ íŠ¹í™” í…ŒìŠ¤íŠ¸
npx promptfoo eval -c youtube_summary.yaml

# ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ìƒì„¸ ë¡œê·¸)
npx promptfoo eval -c promptfooconfig.yaml --verbose

# ğŸ’¾ ê²°ê³¼ CSV ì €ì¥
npx promptfoo eval -c test.yaml --output ./results/
```

## ì§€ì› ëª¨ë¸

### í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ë“¤
- **OpenAI**: gpt-3.5-turbo, gpt-4, gpt-4o ë“±
- **Google**: gemini-flash, gemini-pro ë“±
- **Perplexity**: perplexity-sonar ë“±
- **Ollama**: ollama/gemma3:12b ë“± (ë¡œì»¬ ì„¤ì¹˜ í•„ìš”)

### ëª¨ë¸ ì¶”ê°€í•˜ê¸°

1. **litellm_provider.py**ì—ì„œ ëª¨ë¸ ë§¤í•‘ í™•ì¸
2. **promptfooconfig.yaml**ì—ì„œ provider ì„¤ì • ì¶”ê°€
3. í•´ë‹¹ API í‚¤ë¥¼ **.env**ì— ì¶”ê°€

## í”„ë¡¬í”„íŠ¸ ë° í…ŒìŠ¤íŠ¸ êµ¬ì„±

### í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤
- `prompts/basic.txt`: ê¸°ë³¸ ì„¤ëª… í”„ë¡¬í”„íŠ¸
- `prompts/summary/`: ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë“¤
- `prompts/analysis.txt`: ë¶„ì„ ì „ìš© í”„ë¡¬í”„íŠ¸

### ì¿¼ë¦¬ íŒŒì¼ë“¤
- `queries/summary_query.txt`: ìš”ì•½ ê´€ë ¨ ì§ˆë¬¸
- `queries/analysis_query.txt`: ë¶„ì„ ê´€ë ¨ ì§ˆë¬¸

### í‰ê°€ ë°©ì‹
- **LLM Rubric í‰ê°€**: GPT-4oë¥¼ í‰ê°€ìë¡œ ì‚¬ìš©í•œ ìë™ í’ˆì§ˆ í‰ê°€
- **í‰ê°€ ê¸°ì¤€**: `prompts/single_evaluation_rubric.txt`ì— ì •ì˜

## ì„¤ì • íŒŒì¼ ìƒì„¸

### promptfooconfig.yaml êµ¬ì¡°

```yaml
providers:
  - id: file://./custom-litellm-provider.js

tests:
  - description: "í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ìš”ì•½ í’ˆì§ˆ ë¹„êµ"
    prompts:
      - "prompts/basic.txt"
      - "prompts/summary/summary_prompt.txt"
    vars:
      query: file://queries/summary_query.txt
    providers:
      - id: file://./custom-litellm-provider.js
        config:
          model: gpt-3.5-turbo
    assert:
      - type: llm-rubric
        value: file://prompts/single_evaluation_rubric.txt
        provider: file://./custom-litellm-provider.js
        config:
          model: gpt-4o
```

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜ë“¤

1. **"promptê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"**
   - ì›ì¸: í…œí”Œë¦¿ ë³€ìˆ˜ ì²˜ë¦¬ ì˜¤ë¥˜
   - í•´ê²°: `{{query}}` ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸

2. **API í‚¤ ì˜¤ë¥˜**
   - ì›ì¸: .env íŒŒì¼ì˜ API í‚¤ ë¬¸ì œ
   - í•´ê²°: API í‚¤ ìœ íš¨ì„± í™•ì¸ ë° ì˜¬ë°”ë¥¸ í˜•ì‹ í™•ì¸

3. **ëª¨ë¸ ì¸ì‹ ì˜¤ë¥˜**
   - ì›ì¸: ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ëª… ë˜ëŠ” API í‚¤ ë¶€ì¡±
   - í•´ê²°: ëª¨ë¸ëª… í™•ì¸ ë° í•´ë‹¹ API í‚¤ ì„¤ì •

### ë””ë²„ê·¸ ëª¨ë“œ

```bash
# Python ìŠ¤í¬ë¦½íŠ¸ ë¡œê·¸ í™•ì¸
tail -f debug.log

# ìƒì„¸ ì—ëŸ¬ ë¡œê·¸
npx promptfoo eval --config promptfooconfig.yaml --verbose
```

## í™•ì¥ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ í‰ê°€ ë©”íŠ¸ë¦­ ì¶”ê°€
1. `prompts/` ë””ë ‰í† ë¦¬ì— ìƒˆ rubric íŒŒì¼ ìƒì„±
2. `promptfooconfig.yaml`ì˜ assert ì„¹ì…˜ì— ì¶”ê°€

### ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ ì¶”ê°€
1. `prompts/` ë””ë ‰í† ë¦¬ì— ìƒˆ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ìƒì„±
2. `promptfooconfig.yaml`ì˜ prompts ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

### ë°°ì¹˜ ì²˜ë¦¬ ë° ì„±ëŠ¥ ìµœì í™”
- `--max-concurrency` ì˜µì…˜ìœ¼ë¡œ ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì¡°ì ˆ
- `--repeat` ì˜µì…˜ìœ¼ë¡œ ë°˜ë³µ í…ŒìŠ¤íŠ¸ ì„¤ì •

## ì°¸ê³  ìë£Œ

- [PromptFoo ê³µì‹ ë¬¸ì„œ](https://promptfoo.dev/docs/)
- [LiteLLM ê³µì‹ ë¬¸ì„œ](https://docs.litellm.ai/)
- [ì§€ì›í•˜ëŠ” LLM ëª©ë¡](https://docs.litellm.ai/docs/providers)

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm_promptfoo/
â”œâ”€â”€ promptfooconfig.yaml      # ë©”ì¸ ì„¤ì • íŒŒì¼
â”œâ”€â”€ custom-litellm-provider.js # PromptFoo JavaScript provider
â”œâ”€â”€ litellm_provider.py       # Python LLM í†µí•© ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ .env                      # í™˜ê²½ë³€ìˆ˜ (API í‚¤ë“¤)
â”œâ”€â”€ prompts/                  # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤
â”‚   â”œâ”€â”€ basic.txt
â”‚   â”œâ”€â”€ analysis.txt
â”‚   â”œâ”€â”€ evaluation_rubric.txt
â”‚   â””â”€â”€ summary/
â”œâ”€â”€ queries/                  # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
â”œâ”€â”€ tests/                    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â””â”€â”€ README.md                # ì´ íŒŒì¼
```